# üìò SYSTEM DESIGN DEPTH ‚Äì Tutorial Part 1: Building an End-to-End Scalable Architecture
We‚Äôll cover this in a progressive, layered format.

---

## üîß Use Case: Build a Scalable E-commerce Backend

**Goals:**
- Handle millions of users
- Support product listings, orders, notifications
- Ensure high availability, fault-tolerance, scalability

---

### üß± LAYER 1: High-Level Components

| Component      | Description                                         |
| -------------- | --------------------------------------------------- |
| Client         | React.js web app / Mobile app                       |
| API Gateway    | Entrypoint for all client requests                  |
| Backend APIs   | Node.js + Express services (microservices/monolith) |
| Database       | PostgreSQL (orders, products) + MongoDB (reviews)   |
| Cache          | Redis or Memcached for hot data                     |
| Message Queue  | Kafka (or SQS) for async tasks                      |
| CDN            | CloudFront for static assets                        |

#### üîÅ Request Flow: Order Placement Example

```
Client ‚Üí API Gateway ‚Üí Order Service ‚Üí PostgreSQL
         ‚Ü≥ Kafka (order-events) ‚Üí Notification Service ‚Üí WebSocket
```

---

### üóÉÔ∏è LAYER 2: Database Design

**Product Table (PostgreSQL):**
```sql
products (
  id UUID PRIMARY KEY,
  name TEXT,
  price DECIMAL,
  inventory INT,
  created_at TIMESTAMP
)
```

**Orders Table:**
```sql
orders (
  id UUID,
  user_id UUID,
  product_id UUID,
  quantity INT,
  status TEXT,
  created_at TIMESTAMP
)
```

**Tips:**
- Use UUIDs for distributed ID generation
- Store timestamps for history/metrics
- Index frequently filtered fields (user_id, status)

---

### ‚ö° LAYER 3: Caching Strategy

| Data            | Strategy                          | Tool  |
| --------------- | --------------------------------- | ----- |
| Product Catalog | Cache product data by ID          | Redis |
| Auth Tokens     | Store short-lived session/token   | Redis |
| Rate Limiting   | Track IP/user action counts       | Redis |

**Example (Redis):**
```bash
GET product:1234  ‚ûú  {name: "iPhone", price: 999}
```

---

### üö¶ LAYER 4: Scalability Principles

| Pattern              | Example                                               |
| -------------------- | ---------------------------------------------------- |
| Horizontal Scaling   | Multiple Node.js instances behind load balancer      |
| Stateless Services   | Session in Redis, not app memory                     |
| Queue-Based Async    | Kafka/SQS for email, notification, retry             |
| Database Sharding    | Shard users/orders by region/hash                    |
| Read Replicas        | PostgreSQL replicas for read-heavy ops               |

---

### üîê LAYER 5: Handling Edge Cases

| Problem                  | Solution                                   |
| ------------------------ | ------------------------------------------ |
| Service crashes          | Kubernetes / PM2 + health checks           |
| DB connection overload   | Connection pooling, backoff strategies     |
| Duplicate payments/orders| Idempotency keys (unique client tokens)    |
| Slow catalog loads       | Cache with TTL + background refresh        |

---

### üß™ LAYER 6: Observability & Reliability

- **Logging:** Winston, Morgan ‚Üí ELK stack/CloudWatch
- **Metrics:** Prometheus + Grafana, or AWS CloudWatch
- **Health checks:** `/healthz` endpoints, monitored by LB/K8s
- **Retries & Alerts:** Retries on failure, alerts via PagerDuty/Slack

---

## üîÄ Why Use Two Databases (PostgreSQL + MongoDB)?

**Polyglot persistence:** Use the best tool for each job.

- **PostgreSQL:** Structured, relational data (orders, products, inventory, payments)
  - ACID compliance, relational integrity, schema enforcement
- **MongoDB:** Unstructured/semi-structured data (reviews, logs)
  - Flexible schema, fast writes, no joins

**Example (MongoDB review):**
```json
{
  "productId": "1234",
  "userId": "5678",
  "rating": 4.5,
  "comment": "Great phone!",
  "createdAt": "2024-05-01T10:00:00Z"
}
```

**Summary:**  
Use PostgreSQL for transactional, structured data.  
Use MongoDB for fast, flexible, large-volume storage (logs, reviews).

---

## üß† Redis: Where and How Is Data Stored in Memory?

- **What:** In-memory data structure store (key-value, RAM-based)
- **Where:** Runs as a process on server/container, data in RAM
- **How:** Interact via Redis API

**Example (Node.js):**
```js
await redisClient.set("product:1234", JSON.stringify(productData), "EX", 3600);
```
- Key: `product:1234`
- Value: JSON string
- TTL: 1 hour

**Why Fast:**  
RAM speed, direct key lookups, no SQL parsing.

**Caveats:**  
Volatile (unless persistence enabled), RAM is expensive.

**Summary:**  
SET a key in Redis ‚Üí lives in server RAM, managed by Redis. Fast, but memory-constrained.

---

# üìò SYSTEM DESIGN DEPTH ‚Äì Part 2: API Design, Deployment, and Scalability Patterns

**Focus:**
- API Design (RESTful, security)
- Deployment architecture
- Scalability patterns
- Real-world tradeoffs

---

## ‚úÖ 1. API DESIGN PRINCIPLES

### üß≠ URL Structure (RESTful)

| Operation        | Endpoint                  | Description         |
| ---------------- | ------------------------ | ------------------- |
| Get products     | GET /api/products         | Product list        |
| Get a product    | GET /api/products/:id     | Product details     |
| Create an order  | POST /api/orders          | Place an order      |
| Get user orders  | GET /api/users/:id/orders | Order history       |

### üîí Authentication & Authorization

- Use JWTs or AWS Cognito
- Header: `Authorization: Bearer <JWT_TOKEN>`
- Middleware: `app.use("/api", authenticateJWT);`
- RBAC:  
  ```js
  if (user.role !== "admin") return res.status(403).json({ error: "Forbidden" });
  ```

### üÜî Idempotency

- Prevent double-orders with client-generated idempotency-key:
  ```
  POST /api/orders
  Idempotency-Key: order-abc123
  ```

---

## üöÄ 2. DEPLOYMENT ARCHITECTURE (CLOUD)

### üèóÔ∏è Components

| Component      | Tool                        |
| -------------- | -------------------------- |
| Load Balancer  | AWS ALB or Nginx           |
| App Servers    | EC2 / ECS / EKS            |
| API Gateway    | AWS API Gateway (for Lambda)|
| DB Layer       | RDS PostgreSQL, Mongo Atlas|
| Caching Layer  | ElastiCache (Redis)        |
| File Storage   | S3                         |
| Queue System   | Kafka or SQS               |
| CDN            | CloudFront                 |

### üîÅ Auto-Scaling

- AWS Auto Scaling Groups / ECS Service Autoscaling
- Target-based scaling (e.g., CPU > 60%)

### ‚òÅÔ∏è Deployment Options

- CI/CD: GitHub Actions ‚Üí Docker ‚Üí Terraform/ECS
- Blue-Green Deployment: Run new version in parallel, switch traffic after health checks

---

## üß† 3. SCALABILITY PATTERNS

| Scenario                  | Pattern/Tool                | Benefit                  |
| ------------------------- | --------------------------- | ------------------------ |
| High traffic product pages| Redis caching               | Low-latency reads        |
| Millions of events/orders | Kafka partitioning          | Distributed processing   |
| Peak load on payment      | Queue + async worker        | Smooth spikes            |
| User uploads 1GB file     | Pre-signed S3 URL           | Offload to S3            |
| Slow third-party API      | Queue + retry + circuit breaker | Stability & resilience |

---

## ‚ö†Ô∏è 4. EDGE CASES & TRADEOFFS

| Problem                | Tradeoff                | Strategy                        |
| ---------------------- | ---------------------- | ------------------------------- |
| DB schema changes      | Versioning vs flexibility | Versioned APIs + migrations   |
| Cache stale data       | Speed vs freshness     | TTL + invalidate on updates     |
| Downstream API failure | Simplicity vs reliability | Retry + fallback + circuit breaker |
| Big traffic spikes     | Cost vs elasticity     | Autoscaling + rate limiting     |
| Microservices complexity | Flexibility vs coordination | Loosely coupled services    |

---

# üìä SYSTEM DESIGN DRILLS ‚Äì Real-World Interview Scenarios

**Scenarios:**
1. Product Catalog Service
2. Rate Limiting System
3. Analytics Data Pipeline

---

## üõçÔ∏è 1. Product Catalog Service

**Requirements:**
- List/filter products (category, brand, price)
- Support millions of products
- Fast search, high traffic
- Admins can add/update products

**Architecture:**
```
Client ‚Üí API Gateway ‚Üí Catalog Service ‚Üí DB (PostgreSQL)
                 ‚Ü≥ Redis (cache)
                 ‚Ü≥ Elasticsearch (search)
```

**Data Model (PostgreSQL):**
```sql
products (
  id UUID,
  name TEXT,
  description TEXT,
  price DECIMAL,
  brand TEXT,
  category TEXT,
  created_at TIMESTAMP
)
```

**Caching:**
- Cache hot products/filters in Redis (TTL: 10‚Äì30 mins)
- Invalidate cache on update

**Fast Search:**
- Sync PostgreSQL ‚Üí Elasticsearch
- Index: name, category, brand
- Fuzzy search/filter

**Edge Cases:**
| Problem                | Strategy                  |
| ---------------------- | ------------------------ |
| High read traffic      | Redis + read replicas     |
| Real-time search sync  | Debounce ES sync          |
| Admin updates          | Invalidate/bust cache     |

---

## üö¶ 2. Rate Limiting System (per user/IP)

**Requirements:**
- Allow N requests/user/minute
- Block excess requests
- Lightweight, low-latency

**Architecture:**
```
Client ‚Üí API Gateway ‚Üí Middleware (Rate Limiter) ‚Üí Service
           ‚Ü≥ Redis
```

**Redis Token Bucket:**
- Key: `rate:user123 = 9` (expire in 60s)
- On request: GET, INCR, allow/block, set TTL

**Optimizations:**
- Use Redis Lua script for atomic ops
- Leaky bucket for smoother flow

**Edge Cases:**
- Distributed apps: Use central/shared Redis
- Abuse: Add IP blocking

---

## üìà 3. Analytics Pipeline

**Requirements:**
- Track user events (page views, clicks)
- Process 10M+ events/day
- Store for reporting/dashboard

**Architecture:**
```
Client ‚Üí Event Collector API ‚Üí Kafka ‚Üí Worker
              ‚Ü≥ DB (Raw Events)
                     ‚Ü≥ Aggregation (Daily, Weekly)
              ‚Ü≥ Dashboard API
```

**Kafka Topics:**
- `user-events: { userId, eventType, timestamp, metadata }`
- Retained 7 days

**Storage:**
- Raw: MongoDB/Data Lake
- Aggregated: PostgreSQL/ClickHouse

**Processing:**
- Workers consume from Kafka
- Enrich, aggregate (map-reduce)

**Dashboard:**
- API: `GET /api/analytics/visitors?date=2025-05-01`

**Edge Cases:**
| Problem                | Solution                       |
| ---------------------- | ----------------------------- |
| Spike in event volume  | Kafka partitions + autoscaling |
| Lost events            | Kafka durability, retries      |
| Delayed processing     | Dead-letter topics + alerts    |

---

## üéØ Final Summary

- Design scalable read-heavy systems (catalog)
- Implement low-latency rate limiters (Redis)
- Build real-time/batch analytics pipelines
- Clear component roles, smart tech choices, reliability focus

---

# üì¶ AWS & DevOps ‚Äì Cognito, Lambda, and API Gateway

**Overview:**
| AWS Service | Purpose                                      |
| ----------- | -------------------------------------------- |
| Cognito     | User authentication (sign-up, SSO, JWT)      |
| API Gateway | Expose REST/HTTP APIs securely               |
| Lambda      | Run backend logic, serverless                |

---

## üõ†Ô∏è USE CASE: Build a Secure, Serverless Order Placement API

**Flow:**
```
React App ‚Üí Cognito Login ‚Üí API Gateway ‚Üí Lambda ‚Üí DynamoDB/PostgreSQL
```

---

### ‚úÖ STEP 1: AWS COGNITO ‚Äì USER AUTHENTICATION

- Create user pool (usernames, passwords, attributes)
- Manages login/signup/forgot-password
- Returns JWT tokens

**Setup:**
- Go to Cognito ‚Üí Create User Pool
- Enable email/username login, self-registration, MFA (optional)
- Create App Client (no secret for browser)
- Note User Pool ID, App Client ID, Hosted UI Domain

**Frontend Auth Flow (Node.js):**
```js
import { CognitoUserPool, AuthenticationDetails, CognitoUser } from "amazon-cognito-identity-js";

const poolData = { UserPoolId: "us-east-1_ABC123", ClientId: "abcd1234clientid" };
const userPool = new CognitoUserPool(poolData);

const authDetails = new AuthenticationDetails({ Username, Password });
const user = new CognitoUser({ Username, Pool: userPool });

user.authenticateUser(authDetails, {
  onSuccess: (session) => {
  const accessToken = session.getAccessToken().getJwtToken();
  // Send accessToken to backend in Authorization header
  }
});
```

**Token Header Example:**
```
Authorization: Bearer eyJraWQ... (JWT)
```

---

### ‚úÖ STEP 2: API GATEWAY ‚Äì YOUR GATEKEEPER

- Routes HTTP requests to services (Lambda, ECS, EC2)
- Verifies JWT (from Cognito)
- Supports rate limiting, CORS, caching

**Setup:**
- API Gateway ‚Üí Create HTTP API
- Add Integration: Lambda Function
- Add Route: POST /order
- Attach Cognito Authorizer (User Pool)
- Requires Authorization header

**Request Flow:**
```
[User logs in via Cognito]
‚Üì
[Gets JWT token]
‚Üì
[Client sends token ‚Üí API Gateway ‚Üí validates it]
‚Üì
[Request forwarded to Lambda with user info]
```

---

### ‚úÖ STEP 3: LAMBDA ‚Äì SERVERLESS BACKEND LOGIC

- Runs backend code on demand, scales automatically, billed per request

**Setup:**
- Lambda ‚Üí Create Function (Node.js 18.x)
- Example code:
```js
exports.handler = async (event) => {
  const user = event.requestContext.authorizer.jwt.claims;
  const body = JSON.parse(event.body);

  // Save order to DB (use SDK)
  return {
  statusCode: 200,
  body: JSON.stringify({ message: "Order placed", user })
  };
};
```

**Tips:**
- Log to CloudWatch
- Return proper status codes
- Limit cold starts (provisioned concurrency)

---

### ‚úÖ Final Architecture Recap

```
React App
  ‚Ü≥ User logs in via Cognito
  ‚Ü≥ Gets JWT ‚Üí adds to headers

API Gateway
  ‚Ü≥ Verifies token with Cognito
  ‚Ü≥ Routes request to Lambda

Lambda
  ‚Ü≥ Reads user identity from token
  ‚Ü≥ Places order in DB
```

**Benefits:**
| Benefit         | Why It Matters                        |
| --------------- | ------------------------------------- |
| Fully serverless| No infrastructure to manage           |
| Secure          | Cognito + JWT + API Gateway Auth      |
| Scalable        | Lambda scales automatically           |
| Cost-effective  | Pay-per-request billing               |
| Auditable       | CloudWatch logs + JWT user tracing    |



# üîê AWS COGNITO ‚Äì In-Depth

We‚Äôll break this down into:

- üß† Cognito Architecture
- üßæ Token Types and Their Use
- üîÅ User Auth Flows (Login, Signup, SSO)
- üõ°Ô∏è Token Validation Best Practices
- ‚öôÔ∏è Cognito Triggers (Lambdas for customization)
- ‚ö†Ô∏è Common Pitfalls & Tradeoffs

---

## üß† 1. Cognito Architecture

AWS Cognito has two main components:

| Component     | Purpose                                                        |
| ------------- | -------------------------------------------------------------- |
| User Pools    | Manages user authentication (signup, login, password policies) |
| Identity Pools| Provides temporary AWS credentials via federation (e.g., Google, Azure AD) |

> For most app-level authentication, **User Pools** are used.

---

## üîê 2. Token Types

Cognito issues **three JWTs** when a user logs in:

| Token         | Purpose                        | TTL      | Used For                        |
| ------------- | ----------------------------- | -------- | ------------------------------- |
| `id_token`    | User profile info (name, email)| ~1 hour  | Client-side use                 |
| `access_token`| API access (scopes, groups)    | ~1 hour  | Sent in Authorization header    |
| `refresh_token`| Get new tokens after expiry   | ~30 days | Silent login, token refresh     |

---

## üîÅ 3. Authentication Flows

### üßæ Standard Email/Password Login

1. User enters credentials
2. Cognito authenticates and returns tokens
3. Tokens stored in local/session storage (or HttpOnly cookies)

### üåê SSO with OIDC/SAML (e.g., Azure AD, Google)

1. User clicks ‚ÄúLogin with Google‚Äù
2. Redirected to IdP (Google, Azure)
3. On success, redirected back to Cognito Hosted UI
4. Cognito creates federated user and issues tokens

> ‚úÖ SSO is enabled via Cognito Federation with Identity Pools.

---

## üõ°Ô∏è 4. Token Validation Best Practices

When your backend receives a request:

- Check `Authorization: Bearer <access_token>`
- Validate:
  - **Signature** using Cognito‚Äôs JWKS URL:  
  `https://cognito-idp.{region}.amazonaws.com/{userPoolId}/.well-known/jwks.json`
  - **Issuer** (`iss`) and **audience** (`aud`) claims
  - **Expiration** (`exp`)

**Node.js Example (jsonwebtoken + jwks-rsa):**
```js
const jwt = require("jsonwebtoken");
const jwksClient = require("jwks-rsa");

const client = jwksClient({ jwksUri: COGNITO_JWKS_URL });

function getKey(header, callback) {
  client.getSigningKey(header.kid, (err, key) => {
  callback(null, key.getPublicKey());
  });
}

jwt.verify(token, getKey, { audience: CLIENT_ID, issuer: ISSUER }, (err, decoded) => {
  if (err) return res.status(401).send("Invalid token");
  req.user = decoded;
  next();
});
```

---

## ‚öôÔ∏è 5. Cognito Triggers (Lambdas for Customization)

You can hook Lambda functions into authentication lifecycle events:

| Trigger             | When it Fires             | Example Use Case              |
| ------------------- | ------------------------ | ----------------------------- |
| PreSignUp           | Before user registers     | Block disposable emails       |
| PostConfirmation    | After signup confirmation | Send welcome email            |
| PreAuthentication   | Before login              | IP address checks             |
| DefineAuthChallenge | Customize login challenges| Custom 2FA                    |
| PostAuthentication  | After successful login    | Audit logging, sync profile   |

---

## ‚ö†Ô∏è 6. Common Pitfalls & Tradeoffs

| Issue                        | Recommendation                                         |
| ---------------------------- | ----------------------------------------------------- |
| Token size in headers        | Don‚Äôt send `id_token` to APIs‚Äîuse `access_token` only |
| Cognito Hosted UI is limited | Use custom frontend + Cognito SDK for full control    |
| Federation setup is tricky   | Follow AWS docs for each IdP, test thoroughly         |
| Token expiration issues      | Implement refresh token flow or re-auth after 1hr     |

---

## üß† Summary

- Cognito handles secure, scalable, standards-compliant authentication.
- Use **access tokens** for API auth, validate JWTs on the backend.
- For advanced use cases, leverage triggers and federated identity.
- Always separate authentication (Cognito) from authorization (your backend‚Äôs logic).


-------------

‚öôÔ∏è AWS LAMBDA ‚Äì In-Depth Guide for Backend Engineers  
Lambda lets you run backend logic without provisioning servers, making it a powerful tool for scalable, event-driven apps.

**What We‚Äôll Cover**
- üß† How Lambda Works Internally
- üîÑ Cold Starts, Concurrency, and Scaling
- üì¶ Resource Limits (Memory, Runtime, Timeout)
- üîÅ Retry Behavior, DLQ, and Error Handling
- üîê Security and Permissions (IAM Roles)
- üß™ Monitoring & Best Practices

---

### üß† 1. How AWS Lambda Works (Internals)

What happens when you invoke a Lambda:
- AWS picks a compute node in the background.
- Your function code is loaded in a container (Node.js, Python, etc.).
- The function runs inside a sandboxed environment.
- After execution:
  - The environment is frozen (for reuse)
  - If not used for a while, AWS kills the container

This "freezing and reusing" is key to understanding cold vs warm starts.

---

### ‚ùÑÔ∏è 2. Cold Start vs Warm Start

| Term        | What It Means                                 |
| ----------- | --------------------------------------------- |
| Cold Start  | New Lambda container created (slow: 100ms‚Äì3s+)|
| Warm Start  | Existing container reused (fast: <100ms)      |

**Cold Starts Are Caused By:**
- First request after deployment
- Inactivity (no traffic for ~15 minutes)
- Version or config change

**How to Reduce Cold Starts**
- Use Provisioned Concurrency: Pre-warm N containers
- Use lighter runtimes (Node.js faster than Java)
- Optimize your code:
  - No heavy DB connections on top-level scope
  - Keep packages minimal (bundle only what's used)

---

### ‚öñÔ∏è 3. Resource Limits

| Limit         | Default / Max         |
| ------------- | --------------------- |
| Memory        | 128MB ‚Üí 10GB          |
| CPU           | Proportional to memory|
| Execution Time| Max 15 minutes        |
| Disk Space    | 512MB temporary (/tmp)|
| Payload Size  | 6MB (sync), 256KB (async via SQS)|

> Higher memory = more CPU = faster execution = lower cost sometimes.

---

### üîÅ 4. Retry Behavior and DLQ

| Mode                | Retry Behavior                        |
| ------------------- | ------------------------------------- |
| Sync (API Gateway)  | No retries (caller handles errors)    |
| Async (S3, EventBridge)| Retries 2 times (default)          |
| Queue-based (SQS, Kafka)| Retries until message timeout or maxReceiveCount |

**Dead Letter Queue (DLQ):**
- If retries fail, configure a DLQ (e.g., SQS or SNS) to log failed events.
- Use Lambda Destinations to route failures elsewhere.

---

### üîê 5. Security ‚Äì IAM Roles

Each Lambda function runs with a Lambda execution role, which defines what it can access.

**Example Policy:**
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["s3:GetObject", "dynamodb:PutItem"],
      "Resource": [
        "arn:aws:s3:::my-bucket/*",
        "arn:aws:dynamodb:..."
      ]
    }
  ]
}
```

**Best Practices:**
- Grant least privilege
- Rotate secrets using AWS Secrets Manager
- **Never** hardcode AWS credentials in code

---

### üìä 6. Monitoring, Logs & Best Practices

**Logging**
- All `console.log()` output goes to CloudWatch Logs
- Use structured logging (JSON preferred)

**Metrics**
- Monitor:
  - Duration
  - Invocations
  - Error count
  - Throttles
  - Concurrent executions
- Use CloudWatch Alarms or X-Ray for tracing


# üåê AWS API GATEWAY ‚Äì In-Depth for Backend/System Design

API Gateway is your entry point for all client ‚Üí backend communication in serverless and microservice architectures. It manages routing, security, throttling, and monitoring for APIs.

---

## üìò What We‚Äôll Cover

- üß† How API Gateway Works
- üõ£Ô∏è Types of APIs (REST vs HTTP vs WebSocket)
- üîê Authentication & Authorization
- üö¶ Throttling, Rate Limiting, Caching
- üß∞ Request Transformation (Mapping Templates)
- ü™™ Monitoring, Logging, and Deployment Best Practices

---

## üß† 1. How API Gateway Works

At a high level:

```
Client ‚Üí API Gateway ‚Üí Integration (Lambda / HTTP / AWS Service)
```

API Gateway receives HTTP requests and routes them to:
- AWS Lambda
- Other HTTP endpoints (EC2, external APIs)
- AWS services directly (e.g., S3)

It handles:
- Auth
- Validation
- Rate limiting
- Request/response transformation

---

## üõ£Ô∏è 2. Types of API Gateway APIs

| API Type   | When to Use                   | Notes                                 |
|------------|------------------------------|---------------------------------------|
| HTTP API   | Lightweight, modern REST APIs| Preferred for most use cases          |
| REST API   | Legacy, full features        | Slightly higher latency, more options |
| WebSocket  | Real-time communication      | For chat, live feeds                  |

> **Tip:** Use HTTP APIs for Lambda-based microservices. They're faster, cheaper, and simpler to set up.

---

## üîê 3. Authentication & Authorization

**Options:**

| Method            | How It Works                                 |
|-------------------|----------------------------------------------|
| Cognito           | Validates JWT token in Authorization header  |
| Lambda Authorizer | Custom logic using a Lambda function         |
| IAM               | IAM roles/policies (internal APIs)           |

**Best Practice:**  
For apps using Cognito, attach a Cognito Authorizer in API Gateway:
- User logs in ‚Üí gets JWT
- API Gateway validates token signature, expiry, scopes
- You get user claims in your Lambda‚Äôs `event.requestContext.authorizer.jwt.claims`

---

## üö¶ 4. Throttling, Quotas, and Caching

**Throttling:**  
- Prevent abuse and reduce backend load
- Set limits:  
  - Rate: requests per second (e.g., 100 RPS)
  - Burst: max simultaneous requests

**Quotas:**  
- Per API key (for public APIs)
- Example: 10,000 requests/day per user

**Caching:**  
- Enable response caching for GET endpoints
- TTL: 1s to 3600s
- Stored in in-memory cache at the edge

---

## üß∞ 5. Request/Response Transformation (REST API only)

Mapping Templates let you transform:
- Incoming request into the format your Lambda expects
- Lambda output into a clean client-facing response

**Example: Convert form data into JSON**
```vtl
{
  "username": "$input.params('username')",
  "email": "$input.params('email')"
}
```

---

## ü™™ 6. Monitoring & Best Practices

**Monitoring:**
- AWS CloudWatch Logs (enable per stage)
- Execution metrics: latency, 4xx/5xx errors, integration latency
- X-Ray tracing for performance bottlenecks

**Deployment Best Practices:**

| Feature             | Recommendation                                 |
|---------------------|------------------------------------------------|
| Stages              | Use dev, staging, prod                         |
| Canary Deployments  | Gradually shift traffic using stage variables  |
| Custom Domains      | Map `api.yoursite.com` to Gateway endpoint     |
| Route-based limits  | Use usage plans to control per-user API limits |



# üåÄ Kafka Concepts ‚Äì In-Depth Guide for Backend Engineers

Kafka is the backbone of scalable, event-driven systems. Mastering it is crucial for handling high-throughput, reliable messaging between services.

---

## üìò What You‚Äôll Learn

- üß† Kafka Architecture: Topics, Brokers, Partitions
- üßæ Producer & Consumer Internals
- üë• Consumer Groups & Parallelism
- üîÑ Offset Management & Delivery Semantics
- üìä Use Cases & Real-World Patterns
- ‚ö†Ô∏è Pitfalls & Best Practices

---

## üß† 1. Kafka Architecture

### üîπ Core Components

| Component   | Description                                      |
|-------------|--------------------------------------------------|
| Broker      | Kafka server that stores & serves messages       |
| Topic       | Named stream where messages are published        |
| Partition   | Split within a topic for parallelism & ordering  |
| Producer    | Service that sends messages to a topic           |
| Consumer    | Service that reads messages from a topic         |
| Zookeeper   | (Legacy) manages cluster state (now optional with KRaft mode) |

### üì¶ Topic & Partition Visual

```
Topic: order-events
‚îú‚îÄ‚îÄ Partition 0 ‚Üí [msg1, msg2, msg3]
‚îú‚îÄ‚îÄ Partition 1 ‚Üí [msg4, msg5]
‚îú‚îÄ‚îÄ Partition 2 ‚Üí [msg6, msg7, msg8]
```
Messages in a partition are strictly ordered. Different partitions can be processed in parallel.

---

## üßæ 2. Producer Internals

**Key Responsibilities:**
- Serialize data
- Choose partition (based on key or round-robin)
- Retry if broker is down
- Ensure delivery (acks config)

**Example:**
```js
producer.send({
  topic: "order-events",
  key: "user-123",
  value: JSON.stringify({ orderId: "ORD567" })
});
```
Messages with the same key always go to the same partition = guaranteed ordering per user/order.

---

## üë• 3. Consumer Groups ‚Äì Scaling Consumption

| Feature         | Description                                   |
|-----------------|-----------------------------------------------|
| Consumer Group  | A set of consumers sharing the same groupId   |
| Parallelism     | Kafka divides partitions across consumers      |
| Exclusive Reading | Each partition assigned to one consumer in the group |

**Example:**  
If topic has 3 partitions and 3 consumers in group `checkout-service`:

```
consumer1 ‚Üí Partition 0
consumer2 ‚Üí Partition 1
consumer3 ‚Üí Partition 2
```
‚úÖ Each consumer processes messages independently in parallel.

If there are more consumers than partitions, some consumers are idle.

---

## üîÑ 4. Offset Management & Delivery Semantics

Kafka tracks each consumer‚Äôs offset = ‚Äúlast message read‚Äù.

| Setting             | Description                                      |
|---------------------|--------------------------------------------------|
| auto.offset.reset   | What to do if no offset is found (earliest, latest) |
| enable.auto.commit  | Auto-acknowledge offset after poll               |
| manual commit       | App explicitly calls commit after processing     |

**‚úÖ Best Practice:** Manual offset commit  
Only commit offset after successful processing.  
Prevents data loss on crash.

### üîÅ Delivery Guarantees

| Mode            | Behavior                                                        |
|-----------------|-----------------------------------------------------------------|
| At-most-once    | Fast, but can lose messages if crash before processing          |
| At-least-once   | Safe, but may process message twice (use idempotency)           |
| Exactly-once    | Rare, complex, Kafka supports this with extra config            |

---

## üìä 5. Real-World Use Cases

| Use Case                | Kafka Pattern                                  |
|-------------------------|------------------------------------------------|
| Order placement         | Microservice emits to order-events topic       |
| Email/notification queue| Consumer picks from notification-events        |
| Audit logs              | Centralized logging with Kafka ‚Üí Elasticsearch |
| Analytics pipeline      | Events flow through Kafka to data warehouse    |
| CDC (Change Data Capture)| DB changes ‚Üí Kafka ‚Üí downstream sync          |

---

## ‚ö†Ô∏è 6. Common Pitfalls & Best Practices

| Issue                  | Solution                                         |
|------------------------|--------------------------------------------------|
| Message duplication    | Use idempotent writes (dedupe by ID)             |
| Reprocessing after crash| Use manual offset commit after success          |
| Out-of-order events    | Use same key to keep related events in one partition |
| Idle consumers         | Don‚Äôt exceed number of partitions                |
| Too few partitions     | Harder to scale ‚Üí design for future load (e.g., 20+) |



----------------------------------------------



### üîê SAML vs OAuth 2.0

| Feature         | SAML (Security Assertion Markup Language) | OAuth 2.0 (Open Authorization)      |
|-----------------|-------------------------------------------|-------------------------------------|
| **Purpose**     | Authentication (who you are)              | Authorization (what you can access) |
| **Used For**    | Single Sign-On (SSO) in enterprises       | Delegated access (e.g., login with Google) |
| **Token Format**| XML                                       | JSON (JWT or opaque token)          |
| **Transport**   | Browser redirects, POST                   | HTTP headers, query params, redirects |
| **Common Usage**| Enterprise apps (Okta, AD FS, SAP)        | Mobile/web apps (Google, GitHub, APIs) |
| **User Auth Flow** | IdP sends assertions                   | Client gets access token from auth server |
| **Standard Ports** | Web browser redirects                  | RESTful APIs                        |
### üß† Conceptual Difference

- **SAML** is for enterprise authentication. It tells the app who the user is, often used in SSO (Single Sign-On) scenarios.
- **OAuth 2.0** is for delegated access. It gives an app permission to act on behalf of the user‚Äîoften used with APIs.

#### üîπ Example: SAML

1. Employee logs in to `intranet.company.com`.
2. The app redirects to the corporate IdP (e.g., Okta).
3. A SAML assertion (XML) is POSTed back to the intranet.
4. The user is authenticated and logged in.

#### üîπ Example: OAuth 2.0

1. User clicks ‚ÄúLog in with Google‚Äù.
2. The app redirects to Google with scopes (email, profile).
3. Google shows a consent screen.
4. On success, the app gets an access token.
5. The app can now call Google APIs on behalf of the user.

### üîß When to Use

| Use Case                          | Recommended Protocol                |
|-----------------------------------|-------------------------------------|
| Corporate login & SSO             | ‚úÖ SAML                             |
| Mobile or third-party API access  | ‚úÖ OAuth 2.0                        |
| You control both client & server  | OAuth 2.0 or custom token           |
| Need to pass user identity + claims | SAML or OpenID Connect (on top of OAuth 2.0) |


### ‚úÖ Bonus: What about OpenID Connect?
1. OIDC = OAuth 2.0 + identity layer
2. It fills the authentication gap in OAuth
3. Returns an id_token (JWT) with user info




## üîÑ Quick Recap: What is Sliding Window?

The **sliding window** technique efficiently processes contiguous sequences (windows) within a larger dataset, usually in O(n) time. It‚Äôs ideal for scenarios where you care about recent history or a moving time frame.

---

### ‚úÖ Real-World Use Cases

#### 1. Rate Limiting (Backend, Node.js)
- **Goal:** Limit API requests per user.
- **How:** Track request timestamps in a time window (e.g., last 60 seconds) and allow only N requests.
- **Example:** Sliding window log for 100 requests/user/minute.
- **Tools:** Custom logic or libraries like `express-rate-limit`.

#### 2. Real-Time Analytics / Metrics
- **Goal:** Count events (clicks, transactions) in the last X seconds/minutes.
- **How:** Maintain a queue/array of timestamps, remove old entries as time advances.
- **Example:** Monitor 95th percentile response time over the last 5 minutes.

#### 3. Infinite Scroll / Paginated View (Frontend, React.js)
- **Goal:** Render only visible data in a "window" around the viewport.
- **How:** Use virtualization libraries (`react-window`, `react-virtualized`) to render just what's visible.
- **Example:** Chat messages, product lists, logs.

#### 4. Media Streaming / Buffering (Frontend)
- **Goal:** Buffer video/audio data as playback progresses.
- **How:** Slide the buffer window forward, keeping only the next few seconds of data in memory.
- **Example:** Video player buffering the next 5 seconds.

#### 5. Search Autocomplete / Debouncing User Input
- **Goal:** Avoid spamming API as user types.
- **How:** Debounce input using a time-based sliding window (`setTimeout` + `clearTimeout`).
- **Example:** Show suggestions only after user pauses typing.

#### 6. Financial or Sensor Data Processing
- **Goal:** Compute moving averages, min/max over time-series data.
- **How:** Use a sliding window to efficiently calculate rolling statistics.
- **Example:** 5-minute moving average using a deque.

---

### üß∞ When to Use Sliding Window

- You care about recent or moving time frames.
- You want linear-time performance (O(n)).
- You need stream processing or windowed aggregation.

---

### üîß Example: Node.js Rate Limiter

```js
const requests = {};

function rateLimiter(req, res, next) {
  const userId = req.user.id;
  const now = Date.now();

  if (!requests[userId]) requests[userId] = [];

  // Remove timestamps older than 60 seconds
  requests[userId] = requests[userId].filter(ts => now - ts < 60000);

  if (requests[userId].length >= 100) {
    return res.status(429).send('Too many requests');
  }

  requests[userId].push(now);
  next();
}
```

---

### üß™ Final Thoughts

Sliding window is a practical, real-world technique powering efficient systems‚Äîfrom API rate limiting and analytics to UI rendering and stream processing. It‚Äôs a must-have in every full-stack developer‚Äôs toolkit.




### Question

> **You have a data stream coming every 5 seconds via WebSocket. You have to display this data on a line chart. Eventually, your app crashes due to memory usage. How would you design and implement a performant solution?**

---

### üî∑ High-Level Design (HLD)

**Objective:**  
Display a real-time line chart using WebSocket data every 5 seconds, while ensuring performance and avoiding browser memory overflow.

#### 1. Tech Stack

- **React.js** (functional components, hooks)
- **WebSocket** (persistent connection for data stream)
- **Recharts** or **Chart.js** (for line chart rendering)
- **State management:** `useState`, `useRef`, and optionally `useReducer` or Redux
- **Optional:** Web Workers for data-heavy transformation off the main thread

---

2. Architectural Overview

```
React App
‚îÇ
‚îú‚îÄ‚îÄ WebSocket Layer (data ingestion)
‚îÇ
‚îú‚îÄ‚îÄ Data Buffer (sliding window)
‚îÇ
‚îú‚îÄ‚îÄ Chart Renderer (LineChart)
‚îÇ
‚îî‚îÄ‚îÄ UI Controls (Pause, Resume, Export)
```

---

### üîç Low-Level Design (LLD)

#### 1. WebSocket Setup

```js
useEffect(() => {
  const socket = new WebSocket("wss://your-server-endpoint");

  socket.onmessage = (event) => {
    const data = JSON.parse(event.data);
    if (!pausedRef.current) {
      updateDataBuffer(data);
    }
  };

  return () => socket.close();
}, []);
```

#### 2. Data Buffering (Sliding Window)

```js
const MAX_POINTS = 300; // ~25 minutes of data at 5s intervals
const [dataPoints, setDataPoints] = useState([]);

const updateDataBuffer = (newPoint) => {
  setDataPoints((prev) => {
    const updated = [...prev, newPoint];
    if (updated.length > MAX_POINTS) updated.shift();
    return updated;
  });
};
```
### 3. Pause/Resume Control

```js
const pausedRef = useRef(false);

const togglePause = () => {
  pausedRef.current = !pausedRef.current;
};
```

### 4. Line Chart Rendering

```jsx
<LineChart width={800} height={400} data={dataPoints}>
  <XAxis dataKey="timestamp" />
  <YAxis />
  <Tooltip />
  <Line type="monotone" dataKey="value" stroke="#82ca9d" dot={false} />
</LineChart>
```

---

### üßØ Performance and Memory Optimization

**Problem:** Continuous data inflow can cause memory bloat.

### üõ†Ô∏è Solutions & Enhancements

| Problem                | Solution                                                         |
|------------------------|------------------------------------------------------------------|
| Data keeps growing     | **Sliding window:** Retain only the most recent N data points    |
| UI stuttering          | Use `React.memo`/`useMemo` to avoid unnecessary re-renders       |
| Large payloads         | Offload heavy data transformation to **Web Workers**             |
| Too many re-renders    | **Throttle** data ingestion or chart updates                     |
| Memory leaks           | Clean up WebSocket on unmount via `useEffect` cleanup            |

#### Optional Enhancements

- **Export CSV:** Add a button to download buffered data as CSV.
- **Backpressure Handling:** Drop or queue messages if chart rendering lags.
- **WebSocket Reconnect:** Implement retry logic with exponential backoff.
- **Downsampling:** Render fewer points visually while preserving the chart's shape.

## ‚úÖ Summary
‚ÄúTo handle the streaming data every 5 seconds via WebSocket and render it in a line chart, I set up a persistent WebSocket connection and buffer the data in a sliding window of recent points to prevent memory bloat. I use Recharts for rendering and optimize performance using shallow state updates, throttling, and clean WebSocket disconnection. I also provide pause/resume functionality and can offload any heavy work to a Web Worker if needed. This ensures smooth, real-time UX without performance issues even during long sessions.‚Äù


## Idempotency in Payment APIs

**Idempotency** ensures that multiple identical requests have the same effect as a single request. This is crucial for payment APIs to prevent double-charging users.

### 1. Idempotency Key (Recommended Approach)
- The client sends a unique `Idempotency-Key` header with each request.
- The server checks a persistent store (e.g., Redis, Postgres) for this key:
    - **If found:** Return the previous result (do not re-run the payment logic).
    - **If not found:** Process the payment, save the result with the key, and return the response.
- This approach makes retries (e.g., due to network issues) safe and prevents duplicate charges.

### 2. Database Transaction (Additional Safety)
- Use ACID-compliant transactions (e.g., PostgreSQL, MongoDB sessions) to wrap payment operations.
- This ensures atomicity (e.g., deduct balance and insert payment record together).
- However, this alone does not prevent duplicate external requests‚Äîcombine with an idempotency key for full protection.

### 3. Unique Constraint (Backup)
- Add a unique field (e.g., `transactionId`) in the database.
- Prevents duplicate rows even if application logic fails.

---

## Designing a Rate Limiting System for POST /login

To block abuse (e.g., brute force) while maintaining user experience:

### 1. Types of Rate Limits
- **Per-IP:** Prevents bot abuse.
- **Per-user/email:** Blocks brute-force attacks.
- **Global:** Protects infrastructure from overload.

### 2. Where to Store Rate Data
- **In-memory (App-level):** Fast, but not scalable across multiple instances. Good for prototyping.
- **Centralized (Distributed):** Use Redis for fast, atomic, and consistent rate limiting across all app instances.

### 3. Implementation Layers
- **App-level:** Use packages like `express-rate-limit` or `rate-limiter-flexible`.
- **Infrastructure-level:** Use load balancers or WAFs (e.g., AWS API Gateway, Cloudflare, Nginx) for IP/path-based limits.

### 4. Handling Legitimate vs Malicious Users
- Use exponential backoff or token bucket algorithms.
- Allow bursts, throttle on abuse, and consider CAPTCHA/OTP after excessive attempts.

### 5. Global vs Per-user Limits
- **Global:** Protects the whole system.
- **Per-user/IP:** Targets individual abuse.

---

## Handling CPU-Bound Work in Node.js

### 1. Offloading Heavy Tasks
- Use `worker_threads` to move CPU-intensive work off the main thread.
- For process isolation, use child processes or external services (e.g., AWS Lambda).

### 2. Queueing for High Load
- Use job queues (e.g., RabbitMQ, Bull) to manage and distribute heavy tasks.

---

## Preventing Thread Exhaustion in worker_threads

### 1. Backpressure and Streams
- Use Node.js streams for I/O-heavy tasks to prevent memory bloat.
- Streams handle backpressure automatically.

### 2. Thread Pool Management
- **Do not spawn unlimited workers.**
- Use a thread pool manager (e.g., Piscina) to maintain a fixed number of workers and queue extra tasks.
- Example:
    ```js
    const Piscina = require('piscina');
    const pool = new Piscina({ filename: './worker.js' });
    await pool.runTask(data); // Queues if pool is busy
    ```

### 3. Manual Queue + Semaphore
- Track active workers and only spawn new ones if below a set limit.

**Summary:**  
- Use streams for I/O with built-in backpressure.
- Use thread pools or bounded queues for CPU-heavy tasks to avoid memory exhaustion.

