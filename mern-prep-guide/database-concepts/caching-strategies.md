# ‚ö° Caching Strategies in System Design

Caching is a performance optimization technique to reduce latency, load, and cost by storing frequently accessed data in a fast-access layer (like memory).

---

## üß† Why Use Caching?

- Reduce database load
- Speed up API responses
- Handle high traffic spikes
- Improve user experience

---

## üì¶ Where to Cache? (Cache Levels)

| Level          | Example                          | Use Case                          |
|----------------|----------------------------------|------------------------------------|
| Client-side    | Browser localStorage/sessionStorage | Static assets, user tokens        |
| CDN/Edge       | Cloudflare, Akamai              | Static files like images, JS, CSS |
| Application    | In-memory (e.g., Node.js cache) | Small data, per instance          |
| Distributed    | Redis, Memcached                | Shared, scalable caching layer    |
| Database       | Query cache, materialized views | Expensive queries                 |

---

## üõ†Ô∏è Common Caching Strategies

### 1. Read-Through Cache
App reads from cache ‚Üí if miss, reads from DB, writes to cache.

```js
// Pseudocode
cache.get(key) || db.query().then(result => {
    cache.set(key, result);
    return result;
});
```

- ‚úÖ Always fresh cache
- ‚ùå Extra latency on cache misses

### 2. Write-Through Cache
Every write goes through the cache, which updates the DB.

- ‚úÖ Consistent data
- ‚ùå Slower writes

### 3. Write-Behind (Write-Back)
Write to cache ‚Üí async update to DB later.

- ‚úÖ Very fast writes
- ‚ùå Data loss risk if cache crashes

### 4. Cache Aside (Lazy Loading) 
**‚úÖ Most common**  
App checks cache ‚Üí if miss, loads from DB and writes to cache.

- ‚úÖ Flexible
- ‚ùå Potential stale data

---

## üßπ Cache Invalidation Strategies

| Strategy       | Description                          |
|----------------|--------------------------------------|
| Time-based     | Use TTL (e.g., 60 seconds)           |
| Manual         | Delete key when data is updated in DB|
| Versioning     | Use versioned keys like `user:123:v2`|
| Write-through  | Keep cache and DB always in sync     |

---

## üìç Where to Use Caching in Real Systems?

- **Timeline feed (Twitter, Instagram)** ‚Üí Redis
- **Product catalog (e-commerce)** ‚Üí Memcached
- **Session data** ‚Üí Redis
- **Autocomplete suggestions** ‚Üí In-memory cache

---

## üß® What Happens When Your Cache Goes Down?

- Your app falls back to the database for reads.
- DB load spikes, potentially slowing down or crashing under pressure.
- Response time increases since cached data is no longer instantly available.

### ‚úÖ Mitigations:
- Use circuit breakers or graceful fallbacks.
- Add rate limits or throttling to protect your DB.
- Use redundant caches or multi-layered caching.

---

## üïí How Do You Handle Stale Data?

| Strategy            | How it Works                          | Best For                          |
|---------------------|---------------------------------------|-----------------------------------|
| TTL (Time to Live)  | Set an expiration time on cache keys  | Regularly changing data (e.g., news) |
| Write-through       | Write to DB + cache at same time      | Strong consistency               |
| Cache Invalidation  | Remove/update cache on writes/updates| Manual control                   |
| Background Refresh  | Refresh data periodically in background | Analytics, dashboards          |

**üß† TL;DR:** You balance freshness vs performance; choose based on read/write patterns.

---

## ‚öîÔ∏è Redis vs Memcached ‚Äî When to Use Which?

| Feature         | Redis                        | Memcached                     |
|-----------------|------------------------------|-------------------------------|
| Data Types      | Rich (lists, sets, sorted sets, etc.) | Simple key-value only         |
| Persistence     | ‚úÖ Yes (AOF / RDB snapshots) | ‚ùå No (pure in-memory)         |
| Pub/Sub, Streams| ‚úÖ Yes                       | ‚ùå No                          |
| Memory Usage    | Slightly more               | Slightly more efficient       |
| Use Case        | Counters, sessions, queues, leaderboards | Simple caching (HTML, API responses) |

**üß† TL;DR:** Use Redis for power & features; Memcached for lightweight key-value caching.

---

## üì∏ Where Would You Cache in a Blog/Instagram System?

### Blog System:
- Cache post content, homepage feed, most-read posts
- Cache at API response level or template fragments

### Instagram-like App:
- Cache user profiles, photo metadata, popular posts, feed results
- Use Redis for timeline caching or counting likes/views
- Use CDN for images and videos

**üß† TL;DR:** Cache things that are:
- Read-heavy
- Expensive to compute
- Shared across users


# Caching Strategies Cheat Sheet

## ‚úÖ Why Use Caching?
- Reduce latency
- Decrease load on databases/services
- Improve scalability

---

## üîπ Common Caching Types

### 1. **In-Memory Cache**
- **Tools:** Node.js memory, `lru-cache`, `node-cache`
- **Use When:** Ultra-fast, per-instance caching (e.g., config values, small datasets)
- **Drawback:** Not persistent across app restarts or distributed instances

### 2. **Distributed Cache**
- **Tools:** Redis, Memcached
- **Use When:** Shared cache across multiple app instances/services
- **Supports:** Expiration, pub/sub, persistence (Redis AOF/RDB), eviction policies (LRU, LFU)

---

## üîπ Caching Strategies by Behavior

### 3. **Read-Through Cache**
- **Flow:** App reads from cache ‚Üí If miss, loads from DB ‚Üí Stores in cache ‚Üí Returns result
- **Best For:** Frequently-read data (user profiles, config, product details)
- **Pro:** Automatic population
- **Con:** Initial cache miss may delay response

### 4. **Write-Through Cache**
- **Flow:** App writes to both DB and cache on every update
- **Best For:** When consistency between DB and cache is critical
- **Con:** Slower writes

### 5. **Write-Behind (Write-Back) Cache**
- **Flow:** App writes only to cache ‚Üí Cache asynchronously writes to DB
- **Best For:** High-write systems where write latency matters
- **Con:** Risk of data loss if cache fails before DB write

### 6. **Cache-Aside (Lazy Caching)**
- **Flow:** App tries cache ‚Üí If miss, fetches from DB ‚Üí Stores in cache manually
- **Notes:** Most commonly used strategy; good balance of simplicity and control; often combined with Redis + Node.js

### 7. **Time-Based Expiry / TTL**
- **Description:** Cached items expire after a fixed time
- **Useful For:** News, pricing, or stock info that updates periodically
- **Example:** `Redis.set(key, value, 'EX', 60)`

### 8. **Eviction Policies**
- **When:** Cache exceeds memory limit
- **Types:**
    - **LRU (Least Recently Used):** Default in most libraries
    - **LFU (Least Frequently Used):** More precise for hotspot data
    - **FIFO (First In First Out):** Simple, but not always optimal

---

## üîπ Advanced Strategies

### 9. **Cache Invalidation**
- **Goal:** Remove outdated/stale data from cache correctly
- **Triggers:** Manual (on update/delete), TTL, or version tags
- **Challenge:** Consistency in distributed systems

### 10. **Content Delivery Network (CDN) Caching**
- **Use For:** Static assets (images, CSS, JS, HTML/SSR)
- **Tools:** Cloudflare, AWS CloudFront, Vercel edge cache
- **Benefit:** Cache at edge servers near the user

### 11. **Local Cache + Remote Fallback**
- **Flow:** Use in-process cache first, fallback to Redis or DB if miss
- **Benefit:** Reduces latency and avoids frequent Redis lookups
- **Popular In:** GraphQL resolvers, middleware caching

---

## üî∑ Read-Heavy Use Case

### ‚úÖ Scenario
**Product catalog service for an e-commerce website:**
- 10,000 users browsing products
- Only 500 users making purchases at any time

### üß† Characteristics
- High read-to-write ratio
- Product info changes infrequently
- Need fast response times for UI

### ‚úÖ Caching Strategy
- **Cache-aside (lazy caching) with Redis**
- **TTL:** e.g., 10 minutes
- **Eviction policy:** LRU (evict least accessed)

```ts
// Node.js pseudo-example
const cachedProduct = await redis.get(`product:${productId}`);
if (cachedProduct) return JSON.parse(cachedProduct);

const product = await db.getProduct(productId);
await redis.set(`product:${productId}`, JSON.stringify(product), 'EX', 600); // 10 min TTL
return product;
```

### ‚úÖ Why it works
- Minimizes DB reads
- Redis serves fast responses (low latency)
- TTL ensures eventual consistency
- Stale reads are tolerable (acceptable for product display)

---

## üî∑ Write-Heavy Use Case

### ‚úÖ Scenario
**Real-time analytics event collector:**
- Thousands of events/second being written
- Users rarely read individual events ‚Äî reads happen in batches or aggregated form

### üß† Characteristics
- High write volume
- Low read volume
- Data freshness is critical

### ‚úÖ Caching Strategy
- **Write-back (write-behind) cache or batch buffer**
- Writes go to Redis (or Kafka/queue), then async to DB
- Use TTL carefully or not at all for raw data
- Add deduplication or compression if needed

```ts
// Write to Redis first
await redis.lpush('events', JSON.stringify(eventData));

// Background worker flushes to DB every 5 seconds
```

### ‚úÖ Why it works
- Offloads DB pressure by buffering writes
- Helps absorb spikes without dropping events
- May use Redis Streams, Kafka, or queue + DB batch write

---

## üîÅ Hybrid Example

### ‚úÖ Scenario
**User session service**
- Reads are frequent (check if user is logged in)
- Writes are occasional (login/logout, token refresh)

### Strategy
- Use write-through cache for consistency
- Store session in Redis with expiry
- Read from Redis in every request

---

## üîö Summary

| Use Case   | Read-Heavy                | Write-Heavy                  |
|------------|---------------------------|------------------------------|
| Example    | Product catalog           | Event ingestion / analytics  |
| Strategy   | Cache-aside + TTL         | Write-back / queue-buffer    |
| Cache Type | Redis (GET-first)         | Redis/Kafka (write-first, async DB) |
| Priority   | Low latency for frequent reads | High throughput, DB write protection |
| Eviction   | LRU / TTL                 | Rarely evict (until batch flush)     |
